import cv2
import mediapipe as mp
import av
import time
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration

# ---------------- 1. ê¸°ë³¸ ì„¤ì • ----------------
st.set_page_config(page_title="ì œìŠ¤ì²˜ ìº¡ì²˜", layout="centered")
st.title("âœŒï¸ ì œìŠ¤ì²˜ ìº¡ì²˜ ì¹´ë©”ë¼")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì°ì€ ì‚¬ì§„ ì €ì¥ìš©)
if "snapshot" not in st.session_state:
    st.session_state.snapshot = None

# STUN ì„œë²„ (ë°°í¬ í•„ìˆ˜ ì„¤ì •)
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

# ---------------- 2. ì˜ìƒ ì²˜ë¦¬ ë¡œì§ ----------------
class VictoryProcessor(VideoTransformerBase):
    def __init__(self):
        self.mp_face = mp.solutions.face_detection.FaceDetection(min_detection_confidence=0.6)
        self.mp_hands = mp.solutions.hands.Hands(max_num_hands=2, min_detection_confidence=0.6)
        self.mp_draw = mp.solutions.drawing_utils
        self.last_capture_time = 0
        self.captured_frame = None  # ê°€ì¥ ìµœê·¼ ì°íŒ í”„ë ˆì„ ì €ì¥

    def is_victory(self, lms, w, h):
        # ì¢Œí‘œ ë³€í™˜
        def c(i):
            lm = lms.landmark[i]
            return int(lm.x * w), int(lm.y * h)
        try:
            # ê²€ì§€(8), ì¤‘ì§€(12) í´ì§ / ì•½ì§€(16), ìƒˆë¼(20) ì ‘í˜ í™•ì¸
            if (lms.landmark[8].y < lms.landmark[5].y and 
                lms.landmark[12].y < lms.landmark[9].y and 
                lms.landmark[16].y > lms.landmark[13].y and 
                lms.landmark[20].y > lms.landmark[17].y):
                return True
        except:
            pass
        return False

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img_out = img.copy() # í™”ë©´ ì¶œë ¥ìš© (ì„  ê·¸ë¦¬ê¸°)
        img_h, img_w, _ = img.shape
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # ì–¼êµ´/ì† ì¸ì‹
        face_res = self.mp_face.process(img_rgb)
        hand_res = self.mp_hands.process(img_rgb)
        
        face_detected = face_res.detections is not None
        victory_detected = False

        if hand_res.multi_hand_landmarks:
            for handLms in hand_res.multi_hand_landmarks:
                self.mp_draw.draw_landmarks(img_out, handLms, mp.solutions.hands.HAND_CONNECTIONS)
                if self.is_victory(handLms, img_w, img_h):
                    victory_detected = True

        # ìº¡ì²˜ ì¡°ê±´ ì¶©ì¡± ì‹œ
        current_time = time.time()
        if face_detected and victory_detected:
            # 3ì´ˆ ì¿¨íƒ€ì„
            if current_time - self.last_capture_time > 3.0:
                self.last_capture_time = current_time
                self.captured_frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # ì›ë³¸(ê¹¨ë—í•œ ì´ë¯¸ì§€) ì €ì¥

            # ìº¡ì²˜ ì§í›„ 1ì´ˆ ë™ì•ˆ í™”ë©´ì— í…ìŠ¤íŠ¸ í‘œì‹œ
            if current_time - self.last_capture_time < 1.0:
                 cv2.putText(img_out, "CAPTURED!", (50, 100), 
                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 3)

        return av.VideoFrame.from_ndarray(img_out, format="bgr24")

# ---------------- 3. ë©”ì¸ UI ----------------
col1, col2 = st.columns([2, 1])

with col1:
    st.write("ì™¼ìª½ ì¹´ë©”ë¼ì—ì„œ Vë¥¼ í•˜ì„¸ìš”. 'CAPTURED'ê°€ ëœ¨ë©´ ì˜¤ë¥¸ìª½ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
    # ìŠ¤íŠ¸ë¦¬ë¨¸ ì‹¤í–‰ (keyê°’ ê³ ì •)
    ctx = webrtc_streamer(
        key="snapshot",
        video_processor_factory=VictoryProcessor,
        rtc_configuration=RTC_CONFIGURATION,
        media_stream_constraints={"video": True, "audio": False}
    )

with col2:
    st.write("### ğŸ“¸ ì‚¬ì§„ í™•ì¸")
    
    # [ì‚¬ì§„ ê°€ì ¸ì˜¤ê¸°] ë²„íŠ¼ì„ ëˆŒëŸ¬ì•¼ í”„ë¡œì„¸ì„œ ë‚´ë¶€ì˜ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜´
    if st.button("ì°ì€ ì‚¬ì§„ ê°€ì ¸ì˜¤ê¸°"):
        if ctx.video_processor:
            if ctx.video_processor.captured_frame is not None:
                st.session_state.snapshot = ctx.video_processor.captured_frame
                st.success("ì‚¬ì§„ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
            else:
                st.warning("ì•„ì§ ì°íŒ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤. V í¬ì¦ˆë¥¼ ì·¨í•´ë³´ì„¸ìš”.")
    
    # ê°€ì ¸ì˜¨ ì‚¬ì§„ì´ ìˆìœ¼ë©´ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
    if st.session_state.snapshot is not None:
        st.image(st.session_state.snapshot, caption="ê²°ê³¼ë¬¼", use_column_width=True)
        
        # ì´ë¯¸ì§€ -> ë°”ì´íŠ¸ ë³€í™˜
        img_bgr = cv2.cvtColor(st.session_state.snapshot, cv2.COLOR_RGB2BGR)
        ret, buffer = cv2.imencode('.jpg', img_bgr)
        
        if ret:
            st.download_button(
                label="â¬‡ï¸ íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°",
                data=buffer.tobytes(),
                file_name=f"selfie_{int(time.time())}.jpg",
                mime="image/jpeg"
            )

st.markdown("---")
st.caption("ì‚¬ìš©ë²•: 1. ì¹´ë©”ë¼ ì¼œê¸° -> 2. V í¬ì¦ˆ (CAPTURED ëœ¸) -> 3. 'ì°ì€ ì‚¬ì§„ ê°€ì ¸ì˜¤ê¸°' ë²„íŠ¼ í´ë¦­ -> 4. ì €ì¥")
