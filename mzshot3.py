import cv2
import mediapipe as mp
import av
import time
import queue
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration

# ---------------- 1. ê¸°ë³¸ ì„¤ì • ----------------
st.set_page_config(page_title="AI ìë™ ìº¡ì²˜", layout="centered")
st.title("âœŒï¸ ì œìŠ¤ì²˜ ìë™ ìº¡ì²˜ ì¹´ë©”ë¼")
st.write("ì¹´ë©”ë¼ë¥¼ ì¼œê³  **'V' ì œìŠ¤ì²˜**ë¥¼ í•˜ì„¸ìš”. ìë™ìœ¼ë¡œ ì°íˆê³  ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì´ ëœ¹ë‹ˆë‹¤.")

# STUN ì„œë²„ (ì´ê²Œ ì—†ìœ¼ë©´ ë°°í¬ ì‹œ ê²€ì€ í™”ë©´ë§Œ ëœ¸)
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

# Mediapipe ë¡œë“œ
mp_face = mp.solutions.face_detection
mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils

# ---------------- 2. ì˜ìƒ ì²˜ë¦¬ ë¡œì§ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰) ----------------
class VictoryProcessor(VideoTransformerBase):
    def __init__(self):
        self.face_detector = mp_face.FaceDetection(min_detection_confidence=0.6)
        self.hand_detector = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.6)
        self.result_queue = queue.Queue() # ë©”ì¸ í™”ë©´ìœ¼ë¡œ ì‚¬ì§„ì„ ë³´ë‚´ëŠ” í†µë¡œ
        self.last_capture_time = 0
        self.cooldown = 3.0  # 3ì´ˆ ì¿¨íƒ€ì„

    def is_victory(self, lms, w, h):
        # ì¢Œí‘œ ë³€í™˜ í•¨ìˆ˜
        def c(i):
            lm = lms.landmark[i]
            return int(lm.x * w), int(lm.y * h)

        try:
            # ê²€ì§€(8), ì¤‘ì§€(12) ë
            i_tip, m_tip = c(8), c(12)
            # ì•½ì§€(16), ìƒˆë¼(20) ë
            r_tip, p_tip = c(16), c(20)
            # ê° ì†ê°€ë½ ë§ˆë””
            i_kn, m_kn = c(5), c(9)
            r_kn, p_kn = c(13), c(17)

            # ê²€ì§€/ì¤‘ì§€ëŠ” í´ì§€ê³ (ìœ„), ì•½ì§€/ìƒˆë¼ëŠ” ì ‘í˜(ì•„ë˜)
            # (í™”ë©´ìƒ ìœ„ìª½ì¼ìˆ˜ë¡ yê°’ì´ ì‘ìŒ)
            if (i_tip[1] < i_kn[1] and m_tip[1] < m_kn[1] and 
                r_tip[1] > r_kn[1] and p_tip[1] > p_kn[1]):
                return True
        except:
            pass
        return False

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        
        # ì´ë¯¸ì§€ ë³µì‚¬ (ì“°ê¸° ê°€ëŠ¥í•˜ê²Œ)
        img_out = img.copy()
        img_rgb = cv2.cvtColor(img_out, cv2.COLOR_BGR2RGB)
        img_h, img_w, _ = img_out.shape

        # 1. ì–¼êµ´ ê°ì§€
        face_res = self.face_detector.process(img_rgb)
        face_detected = face_res.detections is not None

        # 2. ì† ê°ì§€
        hand_res = self.hand_detector.process(img_rgb)
        victory_detected = False

        if hand_res.multi_hand_landmarks:
            for handLms in hand_res.multi_hand_landmarks:
                mp_draw.draw_landmarks(img_out, handLms, mp_hands.HAND_CONNECTIONS)
                if self.is_victory(handLms, img_w, img_h):
                    victory_detected = True

        # 3. ìº¡ì²˜ ì¡°ê±´: ì–¼êµ´ O + ë¸Œì´ O + ì¿¨íƒ€ì„ ì§€ë‚¨
        current_time = time.time()
        if face_detected and victory_detected:
            if current_time - self.last_capture_time > self.cooldown:
                self.last_capture_time = current_time
                
                # í™”ë©´ì— í…ìŠ¤íŠ¸ í‘œì‹œ
                cv2.putText(img_out, "CAPTURED!", (50, 100), 
                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 3)
                
                # ì¤‘ìš”: ìº¡ì²˜ëœ ì›ë³¸(ê¹¨ë—í•œ ì´ë¯¸ì§€)ë¥¼ íì— ë„£ìŒ
                # ì„ ì´ ê·¸ë ¤ì§€ì§€ ì•Šì€ ì›ë³¸ì„ ì €ì¥í•˜ê³  ì‹¶ìœ¼ë©´ 'img'ë¥¼ ì‚¬ìš©, 
                # ì„  ê·¸ë ¤ì§„ ê±¸ ì›í•˜ë©´ 'img_out'ì„ ì‚¬ìš©. ì—¬ê¸°ì„  'img_out' ì‚¬ìš©.
                self.result_queue.put(cv2.cvtColor(img_out, cv2.COLOR_BGR2RGB))

        return av.VideoFrame.from_ndarray(img_out, format="bgr24")

# ---------------- 3. ìŠ¤íŠ¸ë¦¬ë° ë° UI ì‹¤í–‰ ----------------
ctx = webrtc_streamer(
    key="snapshot-camera",
    video_processor_factory=VictoryProcessor,
    rtc_configuration=RTC_CONFIGURATION,
    media_stream_constraints={"video": True, "audio": False}
)

# ì‹¤ì‹œê°„ìœ¼ë¡œ í í™•ì¸í•˜ì—¬ ì‚¬ì§„ì´ ì°í˜”ëŠ”ì§€ ê°ì‹œ
if ctx.video_processor:
    if not ctx.video_processor.result_queue.empty():
        # íì—ì„œ ì‚¬ì§„ êº¼ë‚´ê¸°
        captured_img = ctx.video_processor.result_queue.get()
        
        # í™”ë©´ì— í‘œì‹œ
        st.success("ğŸ“¸ ì°°ì¹µ! ì‚¬ì§„ì´ ì´¬ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.image(captured_img, caption="ìº¡ì²˜ëœ ì´ë¯¸ì§€", use_column_width=True)
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„± (ì´ë¯¸ì§€ -> ë°”ì´íŠ¸ ë³€í™˜)
        try:
            is_success, buffer = cv2.imencode(".jpg", cv2.cvtColor(captured_img, cv2.COLOR_RGB2BGR))
            if is_success:
                st.download_button(
                    label="â¬‡ï¸ ì‚¬ì§„ ì €ì¥í•˜ê¸° (Click to Save)",
                    data=buffer.tobytes(),
                    file_name=f"capture_{int(time.time())}.jpg",
                    mime="image/jpeg"
                )
        except Exception as e:
            st.error(f"ì €ì¥ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")

st.markdown("---")
st.caption("PC: Chrome ê¶Œì¥ | Mobile: Safari/Chrome ê¶Œì¥ | ì–¼êµ´ê³¼ ì†ì´ ëª¨ë‘ ë‚˜ì™€ì•¼ ì°í™ë‹ˆë‹¤.")