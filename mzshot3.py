import cv2
import mediapipe as mp
import av
import time
import queue
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration

# ---------------- 1. ê¸°ë³¸ ì„¤ì • ë° ì„¸ì…˜ ì´ˆê¸°í™” ----------------
st.set_page_config(page_title="AI ìë™ ìº¡ì²˜", layout="centered")

# ì‚¬ì§„ ì €ì¥ì†Œ ì´ˆê¸°í™” (ìƒˆë¡œê³ ì¹¨ í•´ë„ ì‚¬ì§„ ìœ ì§€ë˜ë„ë¡)
if "captured_image" not in st.session_state:
    st.session_state["captured_image"] = None

st.title("âœŒï¸ ì œìŠ¤ì²˜ ìë™ ìº¡ì²˜ ì¹´ë©”ë¼")
st.write("ì¹´ë©”ë¼ë¥¼ ì¼œê³  **'V' ì œìŠ¤ì²˜**ë¥¼ í•˜ì„¸ìš”. 3ì´ˆ ë’¤ ë‹¤ì‹œ ì´¬ì˜ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# STUN ì„œë²„ ì„¤ì •
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

# Mediapipe ë¡œë“œ
mp_face = mp.solutions.face_detection
mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils

# ---------------- 2. ì˜ìƒ ì²˜ë¦¬ ë¡œì§ (ë°±ê·¸ë¼ìš´ë“œ) ----------------
class VictoryProcessor(VideoTransformerBase):
    def __init__(self):
        self.face_detector = mp_face.FaceDetection(min_detection_confidence=0.6)
        self.hand_detector = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.6)
        self.result_queue = queue.Queue() # ë©”ì¸ í™”ë©´ìœ¼ë¡œ ì‚¬ì§„ì„ ë³´ë‚´ëŠ” ìš°ì²´í†µ
        self.last_capture_time = 0
        self.cooldown = 3.0  # ì¿¨íƒ€ì„

    def is_victory(self, lms, w, h):
        def c(i):
            lm = lms.landmark[i]
            return int(lm.x * w), int(lm.y * h)
        try:
            # ê²€ì§€(8), ì¤‘ì§€(12) í´ì§ / ì•½ì§€(16), ìƒˆë¼(20) ì ‘í˜
            i_tip, m_tip = c(8), c(12)
            r_tip, p_tip = c(16), c(20)
            i_kn, m_kn = c(5), c(9)
            r_kn, p_kn = c(13), c(17)
            
            return (i_tip[1] < i_kn[1] and m_tip[1] < m_kn[1] and 
                    r_tip[1] > r_kn[1] and p_tip[1] > p_kn[1])
        except:
            return False

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img_out = img.copy()
        img_rgb = cv2.cvtColor(img_out, cv2.COLOR_BGR2RGB)
        img_h, img_w, _ = img_out.shape

        # ì–¼êµ´ & ì† ì¸ì‹
        face_res = self.face_detector.process(img_rgb)
        hand_res = self.hand_detector.process(img_rgb)
        
        face_detected = face_res.detections is not None
        victory_detected = False

        if hand_res.multi_hand_landmarks:
            for handLms in hand_res.multi_hand_landmarks:
                mp_draw.draw_landmarks(img_out, handLms, mp_hands.HAND_CONNECTIONS)
                if self.is_victory(handLms, img_w, img_h):
                    victory_detected = True

        # ìº¡ì²˜ ë¡œì§
        current_time = time.time()
        if face_detected and victory_detected:
            if current_time - self.last_capture_time > self.cooldown:
                self.last_capture_time = current_time
                
                # 'CAPTURED' í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                cv2.putText(img_out, "CAPTURED!", (50, 100), 
                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 3)
                
                # â˜… ì¤‘ìš”: í(ìš°ì²´í†µ)ì— ì‚¬ì§„ ë„£ê¸°
                # img: ì„  ì—†ëŠ” ì›ë³¸ / img_out: ì„  ê·¸ë ¤ì§„ ë²„ì „
                self.result_queue.put(cv2.cvtColor(img_out, cv2.COLOR_BGR2RGB))
                
        return av.VideoFrame.from_ndarray(img_out, format="bgr24")

# ---------------- 3. ë©”ì¸ í™”ë©´ UI ë° ëŒ€ê¸° ë¡œì§ ----------------

# ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë¨¸ ì‹¤í–‰
ctx = webrtc_streamer(
    key="snapshot-camera",
    video_processor_factory=VictoryProcessor,
    rtc_configuration=RTC_CONFIGURATION,
    media_stream_constraints={"video": True, "audio": False}
)

# â˜… ì—¬ê¸°ê°€ í•µì‹¬: ì¹´ë©”ë¼ê°€ ì¼œì ¸ ìˆëŠ” ë™ì•ˆ ì‚¬ì§„ì´ ì˜¤ë‚˜ ê³„ì† ê°ì‹œí•˜ëŠ” ë£¨í”„
if ctx.state.playing:
    # íì—ì„œ ë°ì´í„°ë¥¼ êº¼ë‚´ì˜¬ ë•Œê¹Œì§€ ë°˜ë³µ
    while True:
        if ctx.video_processor:
            try:
                # 0.1ì´ˆ ë™ì•ˆ ê¸°ë‹¤ë ¤ë´„
                result = ctx.video_processor.result_queue.get(timeout=0.1)
            except queue.Empty:
                result = None
            
            # ì‚¬ì§„ì´ ë„ì°©í–ˆìœ¼ë©´?
            if result is not None:
                st.session_state["captured_image"] = result # ì €ì¥
                st.rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨ (ì¦‰ì‹œ í‘œì‹œí•˜ê¸° ìœ„í•´)
                break # ë£¨í”„ íƒˆì¶œ
        
        # CPU ê³¼ë¶€í•˜ ë°©ì§€ìš© ì ì‹œ ëŒ€ê¸°
        time.sleep(0.1) 

# ---------------- 4. ì‚¬ì§„ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ ----------------
st.markdown("---")
if st.session_state["captured_image"] is not None:
    st.success("ğŸ“¸ ì‚¬ì§„ì´ ì´¬ì˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì´ë¯¸ì§€ í‘œì‹œ
    st.image(st.session_state["captured_image"], caption="ë°©ê¸ˆ ì°ì€ ì‚¬ì§„", use_column_width=True)
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë§Œë“¤ê¸°
    # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    img_bgr = cv2.cvtColor(st.session_state["captured_image"], cv2.COLOR_RGB2BGR)
    is_success, buffer = cv2.imencode(".jpg", img_bgr)
    
    if is_success:
        st.download_button(
            label="â¬‡ï¸ ì‚¬ì§„ ë‚´ ì»´í“¨í„°ì— ì €ì¥í•˜ê¸°",
            data=buffer.tobytes(),
            file_name=f"capture_{int(time.time())}.jpg",
            mime="image/jpeg"
        )
else:
    st.write("ì•„ì§ ì°íŒ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤. Vë¥¼ í•´ë³´ì„¸ìš”!")
